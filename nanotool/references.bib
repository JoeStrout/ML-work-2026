% ============================================
% NEUROEVOLUTION AND EVOLUTION STRATEGIES
% ============================================

@article{such2017deep,
  title={Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning},
  author={Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1712.06567},
  year={2017},
  note={Uber AI Labs}
}

@article{salimans2017evolution,
  title={Evolution Strategies as a Scalable Alternative to Reinforcement Learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017},
  note={OpenAI}
}

@article{stanley2002evolving,
  title={Evolving Neural Networks through Augmenting Topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  journal={Evolutionary Computation},
  volume={10},
  number={2},
  pages={99--127},
  year={2002},
  publisher={MIT Press}
}

@inproceedings{gaier2019weight,
  title={Weight Agnostic Neural Networks},
  author={Gaier, Adam and Ha, David},
  booktitle={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{hansen2001completely,
  title={Completely Derandomized Self-Adaptation in Evolution Strategies},
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  journal={Evolutionary Computation},
  volume={9},
  number={2},
  pages={159--195},
  year={2001},
  publisher={MIT Press}
}

@article{hansen2016cma,
  title={The CMA Evolution Strategy: A Tutorial},
  author={Hansen, Nikolaus},
  journal={arXiv preprint arXiv:1604.00772},
  year={2016}
}

@book{risi2025neuroevolution,
  title={Neuroevolution: Harnessing Creativity in AI Model Design},
  author={Risi, Sebastian and Ha, David and Tang, Yujin and Miikkulainen, Risto},
  year={2025},
  publisher={MIT Press}
}

@article{floreano2008neuroevolution,
  title={Neuroevolution: from architectures to learning},
  author={Floreano, Dario and D{\"u}rr, Peter and Mattiussi, Claudio},
  journal={Evolutionary Intelligence},
  volume={1},
  number={1},
  pages={47--62},
  year={2008},
  publisher={Springer}
}

@article{stanley2019designing,
  title={Designing neural networks through neuroevolution},
  author={Stanley, Kenneth O and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
  journal={Nature Machine Intelligence},
  volume={1},
  number={1},
  pages={24--35},
  year={2019},
  publisher={Nature Publishing Group}
}

% ============================================
% NEURAL NETWORKS AND ARITHMETIC
% ============================================

@inproceedings{power2022grokking,
  title={Grokking: Generalization beyond Overfitting on Small Algorithmic Datasets},
  author={Power, Alethea and Burda, Yuri and Edwards, Harrison and Babuschkin, Igor and Misra, Vedant},
  booktitle={ICLR 2022 Workshop on MATH-AI},
  year={2022}
}

@inproceedings{nanda2023progress,
  title={Progress measures for grokking via mechanistic interpretability},
  author={Nanda, Neel and Chan, Lawrence and Lieberum, Tom and Smith, Jess and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{gromov2023grokking,
  title={Grokking modular arithmetic},
  author={Gromov, Andrey},
  journal={arXiv preprint arXiv:2301.02679},
  year={2023}
}

@article{nogueira2021investigating,
  title={Investigating the Limitations of Transformers with Simple Arithmetic Tasks},
  author={Nogueira, Rodrigo and Jiang, Zhiying and Lin, Jimmy},
  journal={arXiv preprint arXiv:2102.13019},
  year={2021}
}

@inproceedings{trask2018neural,
  title={Neural Arithmetic Logic Units},
  author={Trask, Andrew and Hill, Felix and Reed, Scott and Rae, Jack and Dyer, Chris and Blunsom, Phil},
  booktitle={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{testolin2024can,
  title={Can Neural Networks Do Arithmetic? A Survey on the Elementary Numerical Skills of State-of-the-Art Deep Learning Models},
  author={Testolin, Alberto},
  journal={Applied Sciences},
  volume={14},
  number={2},
  pages={744},
  year={2024},
  publisher={MDPI}
}

% ============================================
% TOOL USE IN NEURAL NETWORKS / LLMS
% ============================================

@inproceedings{schick2023toolformer,
  title={Toolformer: Language Models Can Teach Themselves to Use Tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@inproceedings{gao2023pal,
  title={PAL: Program-aided Language Models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}

@article{nye2021show,
  title={Show Your Work: Scratchpads for Intermediate Computation with Language Models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

% ============================================
% MEMORY-AUGMENTED NEURAL NETWORKS
% ============================================

@article{graves2014neural,
  title={Neural Turing Machines},
  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal={arXiv preprint arXiv:1410.5401},
  year={2014}
}

@article{graves2016hybrid,
  title={Hybrid computing using a neural network with dynamic external memory},
  author={Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
  journal={Nature},
  volume={538},
  number={7626},
  pages={471--476},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{rasekh2020ednc,
  title={EDNC: Evolving Differentiable Neural Computers},
  author={Rasekh, Masoud Sabet and Safi-Esfahani, Faramarz},
  journal={Neurocomputing},
  volume={412},
  pages={514--542},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{reed2015neural,
  title={Neural Programmer-Interpreters},
  author={Reed, Scott and de Freitas, Nando},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

% ============================================
% NON-DIFFERENTIABLE COMPONENTS
% ============================================

@article{bengio2013estimating,
  title={Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@inproceedings{jang2017categorical,
  title={Categorical Reparameterization with Gumbel-Softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@inproceedings{maddison2017concrete,
  title={The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},
  author={Maddison, Chris J and Mnih, Andriy and Teh, Yee Whye},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@article{williams1992simple,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Williams, Ronald J},
  journal={Machine Learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

% ============================================
% MODULAR NEURAL NETWORKS
% ============================================

@inproceedings{andreas2016neural,
  title={Neural Module Networks},
  author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={39--48},
  year={2016}
}

@article{pfeiffer2024modular,
  title={Modular Deep Learning},
  author={Pfeiffer, Jonas and Ruder, Sebastian and Vulic, Ivan and Ponti, Edoardo Maria},
  journal={arXiv preprint arXiv:2302.11529},
  year={2024}
}

@article{kirsch2018modular,
  title={Modular Networks: Learning to Decompose Neural Computation},
  author={Kirsch, Louis and Kunze, Julius and Barber, David},
  booktitle={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{goyal2024dynamics,
  title={Dynamics of specialization in neural modules under resource constraints},
  author={Goyal, Anirudh and others},
  journal={Nature Communications},
  volume={15},
  year={2024},
  publisher={Nature Publishing Group}
}

% ============================================
% NEURO-SYMBOLIC AI
% ============================================

@article{garcez2023neurosymbolic,
  title={Neurosymbolic AI: The 3rd Wave},
  author={Garcez, Artur d'Avila and Lamb, Luis C},
  journal={Artificial Intelligence Review},
  volume={56},
  number={11},
  pages={12387--12406},
  year={2023},
  publisher={Springer}
}

@inproceedings{manhaeve2018deepproblog,
  title={DeepProbLog: Neural Probabilistic Logic Programming},
  author={Manhaeve, Robin and Dumancic, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
  booktitle={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{li2023scallop,
  title={Scallop: A Language for Neurosymbolic Programming},
  author={Li, Ziyang and Huang, Jiani and Naik, Mayur},
  booktitle={Proceedings of the ACM on Programming Languages},
  volume={7},
  number={PLDI},
  pages={1--25},
  year={2023}
}

% ============================================
% REINFORCEMENT LEARNING FOUNDATIONS
% ============================================

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{schulman2017proximal,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

% ============================================
% NUMBER REPRESENTATIONS
% ============================================

@article{wallace2019numeracy,
  title={Do NLP Models Know Numbers? Probing Numeracy in Embeddings},
  author={Wallace, Eric and Wang, Yizhong and Li, Sujian and Singh, Sameer and Gardner, Matt},
  journal={arXiv preprint arXiv:1909.07940},
  year={2019}
}

@inproceedings{jiang2020learning,
  title={Learning Numeral Embedding},
  author={Jiang, Chengyue and Narasimhan, Karthik and Bansal, Mohit},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  year={2020}
}

% ============================================
% NEURAL ARCHITECTURE SEARCH
% ============================================

@article{elsken2019neural,
  title={Neural Architecture Search: A Survey},
  author={Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  journal={The Journal of Machine Learning Research},
  volume={20},
  number={1},
  pages={1997--2017},
  year={2019}
}

@inproceedings{real2019regularized,
  title={Regularized Evolution for Image Classifier Architecture Search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={4780--4789},
  year={2019}
}

% ============================================
% ES/GA SCALING AND HYBRID METHODS
% ============================================

@article{eggroll2024,
  title={EGGROLL: Scaling Evolution Strategies to Hyperscale},
  author={Anonymous},
  journal={arXiv preprint arXiv:2511.16652},
  year={2024},
  note={Scales ES to billions of parameters via low-rank perturbations}
}

@article{conti2018improving,
  title={Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents},
  author={Conti, Edoardo and Madhavan, Vashisht and Such, Felipe Petroski and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{conti2018hybrid,
  title={Non-Differentiable Supervised Learning with Evolution Strategies and Hybrid Methods},
  author={Conti, Edoardo and Madhavan, Vashisht and Such, Felipe Petroski and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1906.03139},
  year={2018},
  note={Hybrid ES+backprop for supervised learning; ES 1000x slower than backprop alone}
}

@article{mandischer2002comparison,
  title={A comparison of evolution strategies and backpropagation for neural network training},
  author={Mandischer, Martin},
  journal={Neurocomputing},
  volume={42},
  number={1-4},
  pages={87--117},
  year={2002},
  publisher={Elsevier},
  note={ES competes with backprop only on small problems}
}

@article{li2024evolutionary,
  title={Evolutionary Reinforcement Learning: A Survey},
  author={Li, Hui and Wang, Qi and others},
  journal={Intelligent Computing},
  year={2024},
  publisher={AAAS},
  note={Comprehensive survey of ES and GA for RL}
}

@article{weng2019evolution,
  title={Evolution Strategies},
  author={Weng, Lilian},
  journal={Lil'Log},
  year={2019},
  note={Tutorial on ES algorithms and variance reduction techniques}
}
