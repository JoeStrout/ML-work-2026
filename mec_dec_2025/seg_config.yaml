# Configuration for mitochondria segmentation training

# Model
pretrained_checkpoint: "trained_models/lejepa_128d/checkpoint_epoch0800_valloss0.1142.pt"
freeze_encoder: true      # Start with frozen encoder
# Set resume_checkpoint to a checkpoint path, or null to start from scratch
resume_checkpoint: "checkpoints_seg/best_model_dice0.7175.pt"

# Data
patch_size: 128           # Size of training patches
train_samples: 5000       # Number of training samples per epoch
val_samples: 500          # Number of validation samples per epoch

# Training
bs: 32                    # Batch size
epochs: 501               # Number of training epochs
lr: 0.001                 # Learning rate (1e-3)

# Loss
# Class weights for BCE loss (computed as inverse frequency)
# Mitochondria ~7.78%, background ~92.22%
# weights: [1.0, 11.86] for [background, mitochondria]
pos_weight: 11.86         # Weight for positive class (mitochondria)

# Evaluation
eval_every: 5             # Evaluate every N epochs
save_every: 50            # Save checkpoint every N epochs
visualize_every: 25       # Save visualization every N epochs
